{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Logistic Regression with a Neural Network mindset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "# from lr_utils import load_dataset\n",
    "\n",
    "#  % matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File: lr_utils, function: load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File(\"datasets/train_catvnoncat.h5\", \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
    "    \n",
    "    test_dataset = h5py.File(\"datasets/test_catvnoncat.h5\", \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
    "    \n",
    "    classes = np.array(test_dataset[\"list_classes\"][:])\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Overview of the Problem set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 25\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "plt.show()\n",
    "print(\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + \n",
    "      classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") + \"' picture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_flatten = train_set_x_orig.reshape(m_train, -1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(m_test, -1).T\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))\n",
    "print (\"sanity check after reshaping: \" + str(train_set_x_flatten[0:5,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten / 255.\n",
    "test_set_x = test_set_x_flatten / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - General Architecture of the learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L} (a^{(i)}, y^{(i)}) = - y^{(i)} log (a^{(i)} - (1- y^{(i)}) log(1- a^{(i)}) \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "J = \\frac{1}{m} \\sum_{i=1}^{m} \\mathcal{L} (a^{(i)}, y^{(i)}    ) \n",
    "\\end{equation}\n",
    "\n",
    "1. 初始化参数\n",
    "2. 通过最小化代价函数来学习参数\n",
    "3. 使用学习到的参数来对测试集进行预测\n",
    "4. 分析结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Building the parts of our algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1.0 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "# print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    Create a vector of zeros of shape (dim, 1) for w \n",
    "    and initialize b to 0.\n",
    "    \n",
    "    Argument:\n",
    "        dim -- size of the w vector we want (or number of parameters int this case)\n",
    "        \n",
    "    Returns:\n",
    "        w -- initialized vector of shape (dim, 1)\n",
    "        b -- initialized scalar (corresponds to the bias)\n",
    "        \"\"\"\n",
    "    w = np.zeros((dim, 1)) # double brackets\n",
    "    b = 0\n",
    "    \n",
    "    assert(w.shape == (dim, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "# dim = 2\n",
    "# w, b = initialize_with_zeros(dim)\n",
    "# print (\"w = \" + str(w))\n",
    "# print (\"b = \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - 前向和反向传播\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{J}}{\\partial{\\omega}} =  \\frac{1}{m} X {(A-Y)}^T\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{J}}{\\partial{b}} =  \\frac{1}{m} \\sum_{i=1}^{m} ( a^{(i)} - y^{(i)})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above.\n",
    "    \n",
    "    Returns:\n",
    "        cost -- J, negative log-likelihood cost for logistic regression\n",
    "        dw -- gradient for the loss with respect to w, thus same shape as w\n",
    "        db -- gradient for the loss with respect to b, thus same shape as b\n",
    "    \"\"\"\n",
    "    # Forward \n",
    "    m = X.shape[1]\n",
    "    Z = np.dot(w.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    cost = -(1.0/m) * np.sum(Y*np.log(A) + (1-Y)*np.log(1-A))\n",
    "    \n",
    "    # Backward\n",
    "    dw = (1.0/m) * np.dot(X, (A-Y).T)\n",
    "    db = (1.0/m) * np.sum(A-Y)\n",
    "    \n",
    "    assert(dw.shape == w.shape)\n",
    "    assert(db.dtype == float)\n",
    "    cost = np.squeeze(cost)\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    grads = {\"dw\": dw, \n",
    "            \"db\": db}\n",
    "    \n",
    "    return grads, cost\n",
    "    \n",
    "# w, b, X, Y = np.array([[1.],[2.]]), 2., np.array([[1.,2.,-1.],[3.,4.,-3.2]]), np.array([[1,0,1]])\n",
    "# grads, cost = propagate(w, b, X, Y)\n",
    "# print (\"dw = \" + str(grads[\"dw\"]))\n",
    "# print (\"db = \" + str(grads[\"db\"]))\n",
    "# print (\"cost = \" + str(cost))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost=False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "\n",
    "    Arguments:\n",
    "        num_iterations -- number of iterations of the optimization loop\n",
    "        learning_rate -- learning rate of the gradient descent update rule\n",
    "        print_cost -- True to print the loss every 100 steps\n",
    "\n",
    "    Returns:\n",
    "        params -- dictionary containing the weights w and bias b\n",
    "        grads -- dictionary containing the gradients of the weights and bias \n",
    "                with respect to the cost function\n",
    "        costs -- list of all the costs computed during the optimization, \n",
    "                this will be used to plot the learning curve.\n",
    "    \"\"\"\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iterition {}: {}\".format(i, cost))\n",
    "            \n",
    "    params = {\"w\": w, \n",
    "             \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "            \"db\": db}\n",
    "    \n",
    "    return params, grads, costs\n",
    "\n",
    "\n",
    "# params, grads, costs = optimize(w, b, X, Y, n\n",
    "#                                 um_iterations= 500, \n",
    "#                                 learning_rate = 0.009, \n",
    "#                                 print_cost = False)\n",
    "# print (\"w = \" + str(params[\"w\"]))\n",
    "# print (\"b = \" + str(params[\"b\"]))\n",
    "# print (\"dw = \" + str(grads[\"dw\"]))\n",
    "# print (\"db = \" + str(grads[\"db\"]))\n",
    "# print (\"costs = \" + str((np.array(costs)).round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        Y_prediction -- a numpy array (vector) containing all predictions (0/1) \n",
    "            for the examples in X. \n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_predictions = np.zeros((1, m))\n",
    "    w = w.reshape((X.shape[0], 1))\n",
    "    \n",
    "    Z = np.dot(w.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    \n",
    "    for i in range(m):\n",
    "        if A[0, i] > 0.5:\n",
    "            Y_predictions[0, i] = 1\n",
    "        else:\n",
    "            Y_predictions[0, i] = 0\n",
    "    \n",
    "    assert(Y_predictions.shape == (1, m))\n",
    "    \n",
    "    return Y_predictions\n",
    "\n",
    "\n",
    "# w = np.array([[0.1124579],[0.23106775]])\n",
    "# b = -0.3\n",
    "# X = np.array([[1.,-1.1,-3.2],[1.2,2.,0.1]])\n",
    "# print (\"predictions = \" + str(predict(w, b, X)))             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Merge all funcions into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, \n",
    "          num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "    \n",
    "    parameters, grads, costs = optimize(w, b, X_train, Y_train, \n",
    "                                        num_iterations, learning_rate, print_cost)\n",
    "    \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    \n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "    \n",
    "    print(\"训练准确率：{} %\".format(100 - np.mean(np.abs(Y_prediction_train-Y_train)) * 100))\n",
    "    print(\"测试准确率: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "        \"Y_prediction_test\": Y_prediction_test,\n",
    "        \"Y_prediction_train\": Y_prediction_train,\n",
    "        \"w\": w,\n",
    "        \"b\": b,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations = 2000, learning_rate = 0.005, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture that was wrongly classified.\n",
    "index = 1\n",
    "plt.imshow(test_set_x[:,index].reshape((num_px, num_px, 3)))\n",
    "plt.show()\n",
    "# print (\"y = \" + str(test_set_y[0,index]) \n",
    "#        + \", you predicted that it is a \\\"\" \n",
    "#        + classes[d[\"Y_prediction_test\"][0,index]].decode(\"utf-8\") \n",
    "#        +  \"\\\" picture.\")\n",
    "\n",
    "print (\"y = \" + str(test_set_y[0,index])\n",
    "       + \", you predicted that it is a \\\"\"\n",
    "       + classes[int(d[\"Y_prediction_test\"][0:, index])].decode(\"utf-8\")\n",
    "       +  \"\\\" picture.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = np.squeeze(d['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel(\"cost\")\n",
    "plt.xlabel(\"iterations (per hundreds)\")\n",
    "plt.title(\"Learning rate = \" + str(d['learning_rate']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Further analysis (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "for rate in learning_rates:\n",
    "    print(\"learning rate: {}\".format(rate))\n",
    "    models[str(rate)] = model(train_set_x, train_set_y, test_set_x, test_set_y,\n",
    "                                      num_iterations=1500, learning_rate=rate,\n",
    "                                      print_cost=False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "    \n",
    "for rate in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(rate)][\"costs\"]), label=str(models[str(rate)][\"learning_rate\"]))\n",
    "    \n",
    "plt.ylabel(\"cost\")\n",
    "plt.xlabel(\"iterations\")\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.9')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7- Test with your own image (optional0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = \"isacatornot.jpg\"\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "# my_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((1, num_px**2*3)).T\n",
    "    \n",
    "my_image = scipy.misc.imresize(image, size=(num_px, num_px)).reshape((num_px**2*3, 1))\n",
    "my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) \n",
    "      + \", your algorithm predicts a \\\"\" \n",
    "      + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") \n",
    "      +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
