{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Python Basic with Numpy (optional assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1 - Building basic functions with numpy\n",
    "\n",
    "### 1.1 Sigmoid function, np.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute sigmoid of x.\n",
    "    \n",
    "    Argument:\n",
    "        x -- A scalar\n",
    "        \n",
    "    Return:\n",
    "        s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    s = 1.0/(1+ math.exp(-x))\n",
    "    \n",
    "    return s\n",
    "\n",
    "basic_sigmoid(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7311,  0.8808,  0.9526])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x.\n",
    "    \n",
    "    Argument:\n",
    "        x -- A scalar or numpy array of any size.\n",
    "        \n",
    "    Return:\n",
    "        s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    s = 1.0 / (1 + np.exp(-x))\n",
    "    return s\n",
    "\n",
    "sigmoid(np.array([1, 2, 3])).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Sigmoid gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25      ,  0.19661193,  0.10499359,  0.04517666])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def derivative_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the gradient (also called the slope or derivate) of the sigmoid function \n",
    "    with respect to its input x.\n",
    "    You can store the output of the sigmoid function into variables and then use it to \n",
    "    calculate the gradient.\n",
    "    \n",
    "    Argument:\n",
    "        x -- A scalar or numpy array.\n",
    "        \n",
    "    Return:\n",
    "        ds -- The computed gradient.\n",
    "    \"\"\"\n",
    "    s = 1.0 / (1 + np.exp(-x))\n",
    "    ds = s * (1-s)\n",
    "    return ds\n",
    "\n",
    "derivative_sigmoid(np.array([0, 1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Reshaping arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.39198431  0.10046023]\n",
      "  [ 0.31683415  0.3854926 ]\n",
      "  [ 0.01825868  0.74008314]]\n",
      "\n",
      " [[ 0.30652516  0.73750956]\n",
      "  [ 0.30883552  0.25618362]\n",
      "  [ 0.93577042  0.06871725]]\n",
      "\n",
      " [[ 0.87789599  0.16442596]\n",
      "  [ 0.54854824  0.28195541]\n",
      "  [ 0.63825586  0.94875713]]]\n",
      "[[ 0.39198431]\n",
      " [ 0.10046023]\n",
      " [ 0.31683415]\n",
      " [ 0.3854926 ]\n",
      " [ 0.01825868]\n",
      " [ 0.74008314]\n",
      " [ 0.30652516]\n",
      " [ 0.73750956]\n",
      " [ 0.30883552]\n",
      " [ 0.25618362]\n",
      " [ 0.93577042]\n",
      " [ 0.06871725]\n",
      " [ 0.87789599]\n",
      " [ 0.16442596]\n",
      " [ 0.54854824]\n",
      " [ 0.28195541]\n",
      " [ 0.63825586]\n",
      " [ 0.94875713]]\n"
     ]
    }
   ],
   "source": [
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    Vectorization of an image.\n",
    "    \n",
    "    Argument:\n",
    "        image -- a numpy array of shape (length, height, depth)\n",
    "        \n",
    "    Return:\n",
    "         v -- a vector of shape (length * height * depth, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    v = image.reshape((image.shape[0] * image.shape[1] * image.shape[2], 1))\n",
    "    # v = image.reshape((np.prod(np.array(image.shape)) , 1))\n",
    "    return v\n",
    "\n",
    "\n",
    "image_test = np.random.rand(3, 3, 2)\n",
    "print(image_test)\n",
    "print(image2vector(image_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Normalizing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.6       ,  0.8       ],\n",
       "       [ 0.13736056,  0.82416338,  0.54944226]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizeRows(x):\n",
    "    \"\"\"\n",
    "    Implement a function that normalizes each rows of the matrix x (to have unit length).\n",
    "    \n",
    "    Argument:\n",
    "        x -- A numpy matrix of shape (n, m)\n",
    "        \n",
    "    Return:\n",
    "        x -- The normalized (by row) numpy matrix.\n",
    "             You are allowed to modify x.\n",
    "    \"\"\"\n",
    "    x_norm = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    x = x / x_norm\n",
    "    return x\n",
    "\n",
    "x = np.array([[0, 3, 4],\n",
    "              [1, 6, 4]])\n",
    "normalizeRows(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Broadcasting and the Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.80897665e-01,   8.94462891e-04,   1.79657674e-02,\n",
       "          1.21052389e-04,   1.21052389e-04],\n",
       "       [  8.78679856e-01,   1.18916387e-01,   8.01252314e-04,\n",
       "          8.01252314e-04,   8.01252314e-04]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Compute the softmax for each row of the input x.\n",
    "    \n",
    "    Argument:\n",
    "        x -- A numpy matrix of shape (n, m).\n",
    "    Return:\n",
    "        s -- A numpy matrix equal to the softmax of x, of shape (n, m).\n",
    "    \"\"\"\n",
    "    x_exp = np.exp(x)\n",
    "    x_exp_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "    s = x_exp / x_exp_sum\n",
    "    return s\n",
    "\n",
    "x = np.array([[9, 2, 5, 0, 0], \n",
    "              [7, 5, 0, 0, 0]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot = 278\n",
      " ----- Computation time = 0.0ms\n",
      "outer = [[ 81.  18.  18.  81.   0.  81.  18.  45.   0.   0.  81.  18.  45.   0.\n",
      "    0.]\n",
      " [ 18.   4.   4.  18.   0.  18.   4.  10.   0.   0.  18.   4.  10.   0.\n",
      "    0.]\n",
      " [ 45.  10.  10.  45.   0.  45.  10.  25.   0.   0.  45.  10.  25.   0.\n",
      "    0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.]\n",
      " [ 63.  14.  14.  63.   0.  63.  14.  35.   0.   0.  63.  14.  35.   0.\n",
      "    0.]\n",
      " [ 45.  10.  10.  45.   0.  45.  10.  25.   0.   0.  45.  10.  25.   0.\n",
      "    0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.]\n",
      " [ 81.  18.  18.  81.   0.  81.  18.  45.   0.   0.  81.  18.  45.   0.\n",
      "    0.]\n",
      " [ 18.   4.   4.  18.   0.  18.   4.  10.   0.   0.  18.   4.  10.   0.\n",
      "    0.]\n",
      " [ 45.  10.  10.  45.   0.  45.  10.  25.   0.   0.  45.  10.  25.   0.\n",
      "    0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.]]\n",
      " ----- Computation time = 0.0ms\n",
      "elementwise multiplication = [ 81.   4.  10.   0.   0.  63.  10.   0.   0.   0.  81.   4.  25.   0.   0.]\n",
      " ----- Computation time = 0.0ms\n",
      "gdot = [ 25.32141645  26.59991649  29.9079191 ]\n",
      " ----- Computation time = 0.0ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### CLASSIC DOT PRODUCT OF VECTORS IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "for i in range(len(x1)):\n",
    "    dot+= x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### CLASSIC OUTER PRODUCT IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1),len(x2))) # we create a len(x1)*len(x2) matrix with only zeros\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i]*x2[j]\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### CLASSIC ELEMENTWISE IMPLEMENTATION ###\n",
    "tic = time.process_time()\n",
    "mul = np.zeros(len(x1))\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i]*x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### CLASSIC GENERAL DOT PRODUCT IMPLEMENTATION ###\n",
    "W = np.random.rand(3,len(x1)) # Random 3*len(x1) numpy array\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j]*x1[j]\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(gdot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dot = 278\n",
      " ----- Computation time = 0.0ms\n",
      "outer = [[81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [63 14 14 63  0 63 14 35  0  0 63 14 35  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [81 18 18 81  0 81 18 45  0  0 81 18 45  0  0]\n",
      " [18  4  4 18  0 18  4 10  0  0 18  4 10  0  0]\n",
      " [45 10 10 45  0 45 10 25  0  0 45 10 25  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      " ----- Computation time = 0.0ms\n",
      "elementwise multiplication = [81  4 10  0  0 63 10  0  0  0 81  4 25  0  0]\n",
      " ----- Computation time = 0.0ms\n",
      "gdot = [ 25.32141645  26.59991649  29.9079191 ]\n",
      " ----- Computation time = 15.600099999999895ms\n"
     ]
    }
   ],
   "source": [
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### VECTORIZED DOT PRODUCT OF VECTORS ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### VECTORIZED OUTER PRODUCT ###\n",
    "tic = time.process_time()\n",
    "outer = np.outer(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### VECTORIZED ELEMENTWISE MULTIPLICATION ###\n",
    "tic = time.process_time()\n",
    "mul = np.multiply(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "### VECTORIZED GENERAL DOT PRODUCT ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(W,x1)\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(dot) + \"\\n ----- Computation time = \" + str(1000*(toc - tic)) + \"ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Implement the L1 and L2 loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 1.1\n"
     ]
    }
   ],
   "source": [
    "def L1(yhat, y):\n",
    "    \"\"\"\n",
    "    Arguemnts:\n",
    "        yhat -- vector of size m (predicted lables)\n",
    "        y -- vector of size m (true labels)\n",
    "        \n",
    "    Return:\n",
    "        loss -- the value of the L1 loss function defined above\n",
    "    \"\"\"\n",
    "    loss = np.sum(np.abs(y - yhat))\n",
    "    return loss\n",
    "\n",
    "yhat = np.array([.9, .2, .1, .4, .9])\n",
    "# yhat = np.array([9, 2, 1, 4, 9]) / 10.0\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L1 = {}\".format(L1(yhat, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.43\n"
     ]
    }
   ],
   "source": [
    "def L2(yhat, y):\n",
    "    loss = np.sum(np.power(y-yhat, 2))\n",
    "    return loss\n",
    "\n",
    "yhat = np.array([.9, .2, .1, .4, .9])\n",
    "# yhat = np.array([9, 2, 1, 4, 9]) / 10.0\n",
    "y = np.array([1, 0, 0, 1, 1])\n",
    "print(\"L2 = {}\".format(L2(yhat, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
